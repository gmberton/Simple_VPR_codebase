{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup datasets on Colab - only once"
      ],
      "metadata": {
        "id": "uJWTe9GjRHQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code must be executed only the first time that you open Colab; it is needed to unzip the datasets that we provided into your GDrive account so that you can access them in the future\n",
        "\n",
        "NB: BEFORE running this notebook, you must copy the datasets zip into your GDrive. You can use the link that we provided and simply click 'create a copy'. Make sure that you have enough space (roughly 8 GBs)"
      ],
      "metadata": {
        "id": "NhknBP6cRLTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TwmjD6mRcPtc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbff158e-ed41-4590-8555-f5e0cbf271c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# move into your mounted GDrive filesystem\n",
        "%cd /content/drive/MyDrive/datasets\n",
        "\n",
        "# unzip the datasets to /content, so you don't risk going over the GDrive storage limit\n",
        "# this can take a few minutes\n",
        "!unzip -q gsv_xs.zip -d /content\n",
        "!unzip -q tokyo_xs.zip -d /content\n",
        "!unzip -q sf_xs.zip -d /content"
      ],
      "metadata": {
        "id": "6Hc56Wxkpcp7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now remove the zips from your GDrive\n",
        "%rm gsv_xs.zip tokyo_xs.zip sf_xs.zip\n",
        "# and move the unzipped datasets into your GDrive; in this way the next time\n",
        "# you open Colab you can directly access them\n",
        "!mv /content/*_xs /content/drive/MyDrive/datasets"
      ],
      "metadata": {
        "id": "PCpsbwtuQmtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now download the code. It is better if you fork this repo, so that you can push your\n",
        "# modifications. Inside the repo folder you will also find logs of the experiments\n",
        "%cd /content\n",
        "!git clone https://github.com/gmberton/Simple_VPR_codebase\n",
        "%cd /content/Simple_VPR_codebase"
      ],
      "metadata": {
        "id": "1Eb674sQRo_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup environment - every time"
      ],
      "metadata": {
        "id": "718c2aALRZzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every time you restart Colab's kernel, you have to re-install packages and download anything that was not saved into your GDrive"
      ],
      "metadata": {
        "id": "YpOkk8I0RiPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "u9eZYfxzSE8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Simple_VPR_codebase"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJJYyGeemmGm",
        "outputId": "1fe51b7b-9114-437e-f815-967f357cf359"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Simple_VPR_codebase\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwpebDBcDLrO",
        "outputId": "e3e97731-c248-41c0-e552-7e095125dfdd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imageio==2.25.1\n",
            "imageio-ffmpeg==0.4.8\n",
            "imagesize==1.4.1\n",
            "scikit-image==0.19.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is an example of a basic experiments. You can choose to validate on tokyo_xs or sf_xs\n",
        "\n",
        "!python main.py --train_path /path/to/datasets/gsv_xs --val_path /path/to/datasets/tokyo_xs/test --test_path /path/to/datasets/tokyo_xs/test --num_workers 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwlYsjznDLJS",
        "outputId": "7a87da62-b537-42e0-eaba-ec4e56c4136e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100% 44.7M/44.7M [00:00<00:00, 116MB/s]\n",
            "Using 16bit None Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: LOGS/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "2023-03-28 12:27:39.447299: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-28 12:27:43.216432: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-28 12:27:43.216907: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-28 12:27:43.216942: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Validation: 0it [00:00, ?it/s]/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Validation DataLoader 0: 100% 205/205 [00:41<00:00,  4.93it/s]R@1: 15.6, R@5: 35.6, R@10: 47.6, R@20: 57.8\n",
            "Validation DataLoader 0: 100% 205/205 [00:42<00:00,  4.87it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m           R@1           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   15.555555555555555    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m           R@5           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    35.55555555555556    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name    | Type            | Params\n",
            "--------------------------------------------\n",
            "0 | model   | ResNet          | 11.4 M\n",
            "1 | loss_fn | ContrastiveLoss | 0     \n",
            "--------------------------------------------\n",
            "11.4 M    Trainable params\n",
            "0         Non-trainable params\n",
            "11.4 M    Total params\n",
            "22.878    Total estimated model params size (MB)\n",
            "Epoch 0:  76% 900/1182 [17:18<05:25,  1.15s/it, loss=0.984, v_num=0]/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _fit_impl\n",
            "    self._run(model, ckpt_path=self.ckpt_path)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1112, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1191, in _run_stage\n",
            "    self._run_train()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1214, in _run_train\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 267, in advance\n",
            "    self._outputs = self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 187, in advance\n",
            "    batch = next(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/utilities/fetching.py\", line 184, in __next__\n",
            "    return self.fetching_function()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/utilities/fetching.py\", line 265, in fetching_function\n",
            "    self._fetch_next_batch(self.dataloader_iter)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/utilities/fetching.py\", line 280, in _fetch_next_batch\n",
            "    batch = next(iterator)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/supporters.py\", line 569, in __next__\n",
            "    return self.request_next_batch(self.loader_iters)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/supporters.py\", line 581, in request_next_batch\n",
            "    return apply_to_collection(loader_iters, Iterator, next)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/lightning_utilities/core/apply_func.py\", line 51, in apply_to_collection\n",
            "    return function(data, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 628, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 1316, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 1282, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 1120, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 113, in get\n",
            "    if not self._poll(timeout):\n",
            "  File \"/usr/lib/python3.9/multiprocessing/connection.py\", line 257, in poll\n",
            "    return self._poll(timeout)\n",
            "  File \"/usr/lib/python3.9/multiprocessing/connection.py\", line 424, in _poll\n",
            "    r = wait([self], timeout)\n",
            "  File \"/usr/lib/python3.9/multiprocessing/connection.py\", line 931, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.9/selectors.py\", line 416, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Simple_VPR_codebase/main.py\", line 140, in <module>\n",
            "    trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 608, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/call.py\", line 54, in _call_and_handle_interrupt\n",
            "    logger.finalize(\"failed\")\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/lightning_utilities/core/rank_zero.py\", line 27, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 218, in finalize\n",
            "    super().finalize(status)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/lightning_utilities/core/rank_zero.py\", line 27, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/lightning_fabric/loggers/tensorboard.py\", line 277, in finalize\n",
            "    self.experiment.close()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/tensorboard/writer.py\", line 1207, in close\n",
            "    writer.close()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/tensorboard/writer.py\", line 156, in close\n",
            "    self.event_writer.close()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 130, in close\n",
            "    self._async_writer.close()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 185, in close\n",
            "    self._worker.stop()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 214, in stop\n",
            "    self.join()\n",
            "  File \"/usr/lib/python3.9/threading.py\", line 1060, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "Epoch 0:  76%|███████▌  | 900/1182 [17:38<05:31,  1.18s/it, loss=0.984, v_num=0]\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}